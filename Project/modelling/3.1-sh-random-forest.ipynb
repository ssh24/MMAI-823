{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modelling libraries\n",
    "from sklearn import ensemble, model_selection\n",
    "import numerox as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the data working directory\n",
    "os.chdir(os.path.join(os.getcwd(), \"..\", \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the latest numerai dataset\n",
    "# data = nx.download(\"numerai_dataset.zip\")\n",
    "\n",
    "# to make it faster use an existing dataset\n",
    "data = nx.load_zip(\"numerai_dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment settings\n",
    "MODEL_NAME = \"random-forest\"\n",
    "FOLDER_NAME = \"submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the random forest model class offered by numerox\n",
    "class randomforest(nx.Model):\n",
    "\n",
    "    def __init__(self, params, seed=0):\n",
    "        self.p = params\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit_predict(self, dfit, dpre, tournament):\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=self.p['n_estimators'],\n",
    "                  criterion=self.p['criterion'],\n",
    "                  max_features=self.p['max_features'],\n",
    "                  max_depth=self.p['max_depth'],\n",
    "                  min_samples_split=self.p['min_samples_split'],\n",
    "                  min_samples_leaf=self.p['min_samples_leaf'],\n",
    "                  #bootstrap=self.p['bootstrap'],\n",
    "                  random_state=self.seed,\n",
    "                  n_jobs=-1)\n",
    "        clf.fit(dfit.x, dfit.y[tournament])\n",
    "        yhat = clf.predict_proba(dpre.x)[:, 1]\n",
    "        return dpre.ids, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters required for hyper-tuning the model\n",
    "n_estimators = [100, 200, 400]\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "max_depth = [5, 10, 20]\n",
    "min_samples_split = [5, 10]\n",
    "min_samples_leaf = [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of parameters\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "              'criterion': criterion,\n",
    "              'max_features': max_features,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "              'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use grid search cv to find the best parameters\n",
    "train_data = pd.read_csv(os.path.join(os.getcwd(), \"numerai_dataset\", \"numerai_training_data.csv\"), header=0)\n",
    "X_train = np.array(train_data.loc[:, \"feature1\":\"feature50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tournaments\n",
    "tournaments = [\"bernie\"]\n",
    "# , \"elizabeth\", \"jordan\", \"ken\", \"charles\", \"frank\", \"hillary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory to save the submissions\n",
    "os.chdir(os.path.join(os.getcwd(), \"..\", \"modelling\", FOLDER_NAME, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best params for:  bernie\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 254.6min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 998.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 2536.3min\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed: 2657.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'min_samples_leaf': 4, 'n_estimators': 200, 'min_samples_split': 10, 'criterion': 'gini', 'max_features': 'log2', 'max_depth': 5}\n",
      "training info for:  bernie\n",
      "randomforest(min_samples_leaf=4, n_estimators=200, min_samples_split=10, criterion=gini, max_features=log2, max_depth=5)\n",
      "       logloss     auc     acc    ystd   stats        \n",
      "mean  0.692653  0.5181  0.5124  0.0121   tourn  bernie\n",
      "std   0.001023  0.0244  0.0185  0.0004  region   train\n",
      "min   0.689346  0.4573  0.4669  0.0110    eras     120\n",
      "max   0.695414  0.5960  0.5678  0.0130  consis   0.625\n",
      "validation info for:  bernie\n",
      "randomforest(min_samples_leaf=4, n_estimators=200, min_samples_split=10, criterion=gini, max_features=log2, max_depth=5)\n",
      "       logloss     auc     acc    ystd   stats            \n",
      "mean  0.692564  0.5205  0.5144  0.0116   tourn      bernie\n",
      "std   0.000721  0.0168  0.0127  0.0001  region  validation\n",
      "min   0.691389  0.4892  0.4882  0.0114    eras          12\n",
      "max   0.693949  0.5472  0.5346  0.0118  consis    0.666667\n",
      "saving validation info submission for:  bernie\n",
      "done saving validation info\n",
      "model duration (minutes):  2.67611075703\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through each tournament and print the input for train and validation\n",
    "for index in range(0, len(tournaments)):\n",
    "    # initialize tournament modelling timer\n",
    "    start = time.time()\n",
    "    \n",
    "    # get the tournament name\n",
    "    tournament = tournaments[index]\n",
    "    \n",
    "    # set the target name for the tournament\n",
    "    target = \"target_\" + tournament\n",
    "    \n",
    "    # set the y train with the target variable\n",
    "    y_train = train_data.iloc[:, train_data.columns == target].values.reshape(-1,)\n",
    "    \n",
    "    print \"finding best params for: \", tournament\n",
    "    clf = model_selection.GridSearchCV(ensemble.RandomForestClassifier(), parameters, scoring=\"neg_log_loss\", cv=3, n_jobs=-1, verbose=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_params = clf.best_params_\n",
    "    print \"best params: \", best_params\n",
    "    \n",
    "    # create a new random forest model for the tournament\n",
    "    model = randomforest(best_params, seed=123)\n",
    "    \n",
    "    print \"training info for: \", tournament\n",
    "    train = nx.backtest(model, data, tournament, verbosity=1)\n",
    "    \n",
    "    print \"validation info for: \", tournament\n",
    "    validation = nx.production(model, data, tournament, verbosity=1)\n",
    "    \n",
    "    print \"saving validation info submission for: \", tournament\n",
    "    validation.to_csv(MODEL_NAME + \"-\" + tournament + \".csv\")\n",
    "    print \"done saving validation info\"\n",
    "    \n",
    "    # end tournament modelling timer\n",
    "    stop = time.time()\n",
    "    \n",
    "    print \"model duration (minutes): \", ((stop - start)/(1000*60))%60\n",
    "    \n",
    "    print \"\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
